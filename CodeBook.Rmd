---
title: "CodeBook"
output: pdf_document
date: "December 26, 2015"
---

* Code Book for "tidy.txt"

The tidy.txt containsts of 180 records each with 81 variables. Each record is the results of multi-step process that is explained below. These 180 observations are related to 30 subjects performing 6 main activities (30 * 6 = 180). For each subject, there are 79 columns.


# Database Structure

```{r, echo=FALSE}
tidy_data <- read.table("tidyWithLabels.txt")
```

```{r}
str(tidy_data)
```

# Data Source:
This data is the result of processing raw data collected from *UCI HAR DATASET* dataset, In this dataset, there exist 10299 observations related to datacollections related to each of the 30 subjects performing 6 main activities. 

Using a sensory device, sensed data of each subject are collected and recorded in text files. The dataset is delivered as a chunk of test and train dataset (X_test.txt and X_train.txt). 

In the following section, we provide further information about dataset and columns of the dataset.

1. *"Subject"*: Is the ID of the 30 subjects participating in the study whose data reflected in this dataset. The input for this colum is read from 'subject_test.txt' and 'subject_train.txt'.

2. *"Activity"*: There are 6 main activities in this study that represents the subject's activity under study.

* 'WALKING'
* 'WALKING_UPSTAIRS'
* 'WALKING_DOWNSTAIRS'
* 'SITTING'
* 'STANDING'
* 'LAYING'.

For each subject and activity, there are 561 features. Out of 561 features, we select only those variables that have 'mean' or 'std' string in their  names. The results are 79 variables listed below.

 *  tBodyAcc-mean-X 
 *  tBodyAcc-mean-Y 
 *  tBodyAcc-mean-Z 
 *  tBodyAcc-std-X 
 *  tBodyAcc-std-Y 
 *  tBodyAcc-std-Z 
 *  tGravityAcc-mean-X 
 *  tGravityAcc-mean-Y 
 *  tGravityAcc-mean-Z 
 *  tGravityAcc-std-X 
 *  tGravityAcc-std-Y 
 *  tGravityAcc-std-Z 
 *  tBodyAccJerk-mean-X 
 *  tBodyAccJerk-mean-Y 
 *  tBodyAccJerk-mean-Z 
 *  tBodyAccJerk-std-X 
 *  tBodyAccJerk-std-Y 
 *  tBodyAccJerk-std-Z 
 *  tBodyGyro-mean-X 
 *  tBodyGyro-mean-Y 
 *  tBodyGyro-mean-Z 
 *  tBodyGyro-std-X 
 *  tBodyGyro-std-Y 
 *  tBodyGyro-std-Z 
 *  tBodyGyroJerk-mean-X 
 *  tBodyGyroJerk-mean-Y 
 *  tBodyGyroJerk-mean-Z 
 *  tBodyGyroJerk-std-X 
 *  tBodyGyroJerk-std-Y 
 *  tBodyGyroJerk-std-Z 
 *  tBodyAccMag-mean 
 *  tBodyAccMag-std 
 *  tGravityAccMag-mean 
 *  tGravityAccMag-std 
 *  tBodyAccJerkMag-mean 
 *  tBodyAccJerkMag-std 
 *  tBodyGyroMag-mean 
 *  tBodyGyroMag-std 
 *  tBodyGyroJerkMag-mean 
 *  tBodyGyroJerkMag-std 
 *  fBodyAcc-mean-X 
 *  fBodyAcc-mean-Y 
 *  fBodyAcc-mean-Z 
 *  fBodyAcc-std-X 
 *  fBodyAcc-std-Y 
 *  fBodyAcc-std-Z 
 *  fBodyAcc-meanFreq-X 
 *  fBodyAcc-meanFreq-Y 
 *  fBodyAcc-meanFreq-Z 
 *  fBodyAccJerk-mean-X 
 *  fBodyAccJerk-mean-Y 
 *  fBodyAccJerk-mean-Z 
 *  fBodyAccJerk-std-X 
 *  fBodyAccJerk-std-Y 
 *  fBodyAccJerk-std-Z 
 *  fBodyAccJerk-meanFreq-X 
 *  fBodyAccJerk-meanFreq-Y 
 *  fBodyAccJerk-meanFreq-Z 
 *  fBodyGyro-mean-X 
 *  fBodyGyro-mean-Y 
 *  fBodyGyro-mean-Z 
 *  fBodyGyro-std-X 
 *  fBodyGyro-std-Y 
 *  fBodyGyro-std-Z 
 *  fBodyGyro-meanFreq-X 
 *  fBodyGyro-meanFreq-Y 
 *  fBodyGyro-meanFreq-Z 
 *  fBodyAccMag-mean 
 *  fBodyAccMag-std 
 *  fBodyAccMag-meanFreq 
 *  fBodyBodyAccJerkMag-mean 
 *  fBodyBodyAccJerkMag-std 
 *  fBodyBodyAccJerkMag-meanFreq 
 *  fBodyBodyGyroMag-mean 
 *  fBodyBodyGyroMag-std 
 *  fBodyBodyGyroMag-meanFreq 
 *  fBodyBodyGyroJerkMag-mean 
 *  fBodyBodyGyroJerkMag-std 
 *  fBodyBodyGyroJerkMag-meanFreq 
 
 These variables are further processed in our code. We first melted them using subject and activity. So, the results is a dataset that has four columns (Subject, Activity, Variable, Value). Then, this dataset is casted. We calculated mean value of all the 79 variables for each subject. 
 
 The resulting dataset is the final outcome of this analysis. 